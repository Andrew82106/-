{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2998e24bcfde0548"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据集加载\n",
    "\n",
    "PyG是一个基于PyTorch的且用于处理图中不规则结构数据的深度学习计算框架\n",
    "\n",
    "除了出类拔萃的运行速度，PyG中还集成了很多论文中提出的方法（GCN、SGC、GAT、SAGE等）和常用基准数据集，这些数据集包括但不限于：\n",
    "\n",
    "(1)Cora，一个根据科学论文之间相互引用关系而构建的图数据集，论文中的类型分为7类（后面有介绍），共2708篇。\n",
    "\n",
    "(2)Citeseer，论文之间引用信息的数据集，论文分为Agents、AI、DB、IR、ML和HCI 6类，共包含3312篇。\n",
    "\n",
    "(3)Pubmed，生物医学方面的论文搜寻及摘要数据集。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34bc141c763a9107"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:12.928934Z",
     "start_time": "2024-05-27T07:47:12.899572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集名称: Cora()\n",
      "子图数量: 1\n",
      "特征维度: 1433\n",
      "类别数量: 7\n",
      "f节点的个数:{data.num_nodes}\n",
      "f边的条数:{data.num_edges}\n",
      "f节点平均度数:{data.num_edges / data.num_nodes:.2f}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data_name = 'Cora'\n",
    "path = './data'\n",
    "\n",
    "dataset = Planetoid(path, data_name, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "print(\"数据集名称:\", dataset)\n",
    "print(\"子图数量:\", len(dataset))\n",
    "print(\"特征维度:\", dataset.num_features)\n",
    "print(\"类别数量:\", dataset.num_classes)\n",
    "print('f'\"节点的个数:{data.num_nodes}\")\n",
    "print('f'\"边的条数:{data.num_edges}\")\n",
    "print('f'\"节点平均度数:{data.num_edges / data.num_nodes:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['x', 'edge_index', 'y', 'val_mask', 'test_mask', 'train_mask']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:13.017389Z",
     "start_time": "2024-05-27T07:47:13.014777Z"
    }
   },
   "id": "74736e5b2ebc4d93",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2708, 1433])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:13.162849Z",
     "start_time": "2024-05-27T07:47:13.160170Z"
    }
   },
   "id": "c1890b20bde3b5ac",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2708])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:13.632289Z",
     "start_time": "2024-05-27T07:47:13.629766Z"
    }
   },
   "id": "f2bd9afcef8d3e05",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构造正负样本\n",
    "\n",
    "下面我们来构造训练所用的正样本和负样本。\n",
    "\n",
    "为了简化程序设计复杂度，我们依然采用PyG提供的采样组件。\n",
    "\n",
    "有所不同的是，这里我们重构了NeighborSampler类的sample方法来创建带有正样本和负样本的批次。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e60f4d0cfef5d283"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch_cluster import random_walk\n",
    "from torch_geometric.loader import NeighborSampler as Raw\n",
    "from torch_geometric.nn import SAGEConv\n",
    "class NeighborSampler(Raw):\n",
    "    def sample(self, batch):\n",
    "        # 将batch转换为tensor\n",
    "        batch = torch.tensor(batch)\n",
    "        # 获取邻接矩阵的行和列\n",
    "        row, col, _ = self.adj_t.coo()\n",
    "        # 进行随机游走，获取正样本\n",
    "        pos_batch = random_walk(row, col, batch, walk_length=1, coalesced=False)[:, 1]\n",
    "        # 随机采样负样本\n",
    "        neg_batch = torch.randint(0, self.adj_t.size(1), (batch.numel(), ), dtype=torch.long)\n",
    "        # 将正负样本拼接在一起\n",
    "        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
    "        # 调用父类的sample方法，获取邻居采样\n",
    "        return super(NeighborSampler, self).sample(batch)\n",
    "    \n",
    "train_loader = NeighborSampler(data.edge_index, sizes = [10, 10], batch_size = 256, shuffle = True, num_nodes=data.num_nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:14.345826Z",
     "start_time": "2024-05-27T07:47:14.335726Z"
    }
   },
   "id": "6492270beb833800",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "GraphSAGE的小批量(Minibatch)训练是通过邻居节点采样实现的，这使得大规模全连接图的GNN模型训练成为可能。采样操作是借用PyG的torch_geometric.loader.NeighborSampler实现的（第02行），它实际上属于数据加载器，如同“数据抽水机”，train_loader每次都源源不断地给训练集或测试集输送小批量数据（第15行）。\n",
    "\n",
    "对于小批量图中的每个节点，NeighborSampler分别抽取一个直接邻居节点作为正例（第07和第08行），一个随机节点作为负例（第09行）。这样的采样操作和原本PyG提供的NeighborSampler操作有所不同，因此我们需要在继承类中改写这个采样方法，并传回父类。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b30702d95513bf0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc18f895e3cf13e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "            \n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = nn.functional.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "                \n",
    "    def full_forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = nn.functional.dropout(x, p=0, training=self.training)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:53.537464Z",
     "start_time": "2024-05-27T07:47:53.533068Z"
    }
   },
   "id": "c1a40f45ba31d3da",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练参数配置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d099691e9da6a7b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = None\n",
    "model = SAGE(data.num_node_features, hidden_channels=64, num_layers=2)\n",
    "optimer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "x, edge_index = data.x, data.edge_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:54.198811Z",
     "start_time": "2024-05-27T07:47:54.192648Z"
    }
   },
   "id": "31fb7512fc645fee",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练模型模块"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4efee6ae5362827e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        adjs = [adj for adj in adjs]\n",
    "        optimer.zero_grad()\n",
    "        \n",
    "        out = model(x[n_id], adjs)\n",
    "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
    "        \n",
    "        pos_loss = F.logsigmoid((out * pos_out).sum(dim=1)).mean()\n",
    "        neg_loss = F.logsigmoid((-out * neg_out).sum(dim=1)).mean()\n",
    "        loss = -pos_loss - neg_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimer.step()\n",
    "        \n",
    "        total_loss += float(loss) * out.size(0)\n",
    "        \n",
    "        \n",
    "    return total_loss / data.num_nodes\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:54.464418Z",
     "start_time": "2024-05-27T07:47:54.460827Z"
    }
   },
   "id": "261d6ad40775645a",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 测试模型模块"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30cb19935c078c7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "@ torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model.full_forward(x, edge_index)\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(out[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "    val_acc = clf.score(out[data.val_mask], data.y[data.val_mask])\n",
    "    test_acc = clf.score(out[data.test_mask], data.y[data.test_mask])\n",
    "    \n",
    "    return val_acc, test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:47:54.729379Z",
     "start_time": "2024-05-27T07:47:54.725883Z"
    }
   },
   "id": "88873b1ac5e9388e",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型训练流程"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffffb674aa9daa71"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 1.3892, Val: 0.2900, Test: 0.2790\n",
      "Epoch: 02, Loss: 1.3485, Val: 0.5120, Test: 0.5030\n",
      "Epoch: 03, Loss: 1.1911, Val: 0.6000, Test: 0.5940\n",
      "Epoch: 04, Loss: 1.1001, Val: 0.6360, Test: 0.6290\n",
      "Epoch: 05, Loss: 1.0700, Val: 0.6600, Test: 0.6550\n",
      "Epoch: 06, Loss: 1.0633, Val: 0.6560, Test: 0.6680\n",
      "Epoch: 07, Loss: 1.0404, Val: 0.6440, Test: 0.6580\n",
      "Epoch: 08, Loss: 1.0237, Val: 0.6360, Test: 0.6620\n",
      "Epoch: 09, Loss: 0.9951, Val: 0.6440, Test: 0.6810\n",
      "Epoch: 10, Loss: 0.9975, Val: 0.6640, Test: 0.6970\n",
      "Epoch: 11, Loss: 0.9814, Val: 0.6680, Test: 0.7170\n",
      "Epoch: 12, Loss: 0.9879, Val: 0.6440, Test: 0.7110\n",
      "Epoch: 13, Loss: 1.0090, Val: 0.6340, Test: 0.6960\n",
      "Epoch: 14, Loss: 0.9942, Val: 0.6400, Test: 0.6970\n",
      "Epoch: 15, Loss: 0.9608, Val: 0.6440, Test: 0.7060\n",
      "Epoch: 16, Loss: 0.9628, Val: 0.6680, Test: 0.7100\n",
      "Epoch: 17, Loss: 0.9841, Val: 0.6780, Test: 0.7100\n",
      "Epoch: 18, Loss: 0.9642, Val: 0.6940, Test: 0.7250\n",
      "Epoch: 19, Loss: 0.9776, Val: 0.7060, Test: 0.7300\n",
      "Epoch: 20, Loss: 0.9418, Val: 0.7140, Test: 0.7350\n",
      "Epoch: 21, Loss: 0.9374, Val: 0.7200, Test: 0.7370\n",
      "Epoch: 22, Loss: 0.9465, Val: 0.7120, Test: 0.7400\n",
      "Epoch: 23, Loss: 0.9356, Val: 0.7200, Test: 0.7470\n",
      "Epoch: 24, Loss: 0.9264, Val: 0.7240, Test: 0.7480\n",
      "Epoch: 25, Loss: 0.9535, Val: 0.7200, Test: 0.7440\n",
      "Epoch: 26, Loss: 0.9428, Val: 0.7220, Test: 0.7460\n",
      "Epoch: 27, Loss: 0.9403, Val: 0.7160, Test: 0.7520\n",
      "Epoch: 28, Loss: 0.9351, Val: 0.7180, Test: 0.7530\n",
      "Epoch: 29, Loss: 0.9190, Val: 0.7020, Test: 0.7490\n",
      "Epoch: 30, Loss: 0.9349, Val: 0.6980, Test: 0.7380\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 31):\n",
    "    loss = train()\n",
    "    val_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T07:48:09.101687Z",
     "start_time": "2024-05-27T07:47:55.595654Z"
    }
   },
   "id": "9b13ed1c660a9f15",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61b09cd90d0e0665"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torchpython",
   "language": "python",
   "display_name": "TorchPython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
